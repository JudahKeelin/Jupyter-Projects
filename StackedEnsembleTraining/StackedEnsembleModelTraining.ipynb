{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de6bef3c-6505-40c1-bdfa-7a755aab322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core Python libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Scikit‑learn\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve, f1_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "051f9f6e-e59b-4f7c-8ca8-45fb4c3405e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happy: selected 695 features covering 80% importance\n",
      "angry: selected 319 features covering 50% importance\n",
      "disgust: selected 687 features covering 80% importance\n",
      "fearful: selected 352 features covering 50% importance\n",
      "neutral: selected 405 features covering 60% importance\n",
      "sad: selected 683 features covering 80% importance\n"
     ]
    }
   ],
   "source": [
    "# 1) Load & split the raw data\n",
    "df = pd.read_csv(\"openSmile_emobase.csv\")\n",
    "feature_cols = [c for c in df.columns if c != \"emotion\"]\n",
    "X_full = df[feature_cols]\n",
    "y_full = df[\"emotion\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_full, y_full,\n",
    "    test_size=0.33,\n",
    "    stratify=y_full,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 2) Global scaling (fit on train, apply to both)\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "# 3) Per‑emotion cumulative‐importance feature selection\n",
    "emotions = [\"happy\", \"angry\", \"disgust\", \"fearful\", \"neutral\", \"sad\"]\n",
    "cumulative_threshold = {\n",
    "    \"happy\":    0.8,\n",
    "    \"angry\":    0.5,\n",
    "    \"disgust\":  0.8,\n",
    "    \"fearful\":  0.5,\n",
    "    \"neutral\":  0.6,\n",
    "    \"sad\":      0.8\n",
    "}\n",
    "\n",
    "# Containers for emotion‑specific data and selected indices\n",
    "emo_features = {}\n",
    "X_train_emo  = {}\n",
    "X_test_emo   = {}\n",
    "\n",
    "for emo in emotions:\n",
    "    # binary target: 1 if this emotion, else 0\n",
    "    y_bin = (y_train == emo).astype(int)\n",
    "\n",
    "    # fit tree‑based model to get importances\n",
    "    etc = ExtraTreesClassifier(n_estimators=200, random_state=42, n_jobs=-1)\n",
    "    etc.fit(X_train, y_bin)\n",
    "    importances = etc.feature_importances_\n",
    "\n",
    "    # sort features by descending importance\n",
    "    idx_sorted = np.argsort(importances)[::-1]\n",
    "    cum_importance = np.cumsum(importances[idx_sorted])\n",
    "\n",
    "    # find minimal set covering the threshold\n",
    "    num_features = np.searchsorted(cum_importance, cumulative_threshold[emo]) + 1\n",
    "    selected_idx = idx_sorted[:num_features]\n",
    "\n",
    "    # store indices and slice scaled data\n",
    "    emo_features[emo] = [feature_cols[i] for i in selected_idx]\n",
    "    X_train_emo[emo] = X_train[:, selected_idx]\n",
    "    X_test_emo[emo] = X_test[:, selected_idx]\n",
    "\n",
    "    print(f\"{emo}: selected {num_features} features covering {cumulative_threshold[emo]*100:.0f}% importance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d4c3207-3796-4cd2-ad06-1729607bb254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.20051951 -0.29087151  0.20068077 ...  0.85654987 -0.05835925\n",
      "   0.36518685]\n",
      " [ 1.75464923 -0.30460789  1.75486933 ...  0.00884327 -0.04229745\n",
      "  -0.02065442]\n",
      " [-0.69401092 -0.31528689 -0.69386643 ... -0.81393678 -0.93871881\n",
      "  -0.92940236]\n",
      " ...\n",
      " [ 0.30199994 -0.29455885  0.30216647 ... -0.23764047  1.37047068\n",
      "   0.69201431]\n",
      " [-0.69992313 -0.31528689 -0.69977883 ... -0.23410703 -0.93871881\n",
      "  -0.65905197]\n",
      " [ 1.22732984  2.29097946  1.22615312 ... -0.81393678 -0.93871881\n",
      "  -0.92940236]]\n"
     ]
    }
   ],
   "source": [
    "# joblib.dump(scaler, \"D_EmoScaler.pkl\")\n",
    "# joblib.dump(emo_features[\"disgust\"], \"disgust_features.pkl\")\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92114498-506a-45a6-865e-12e011ccc729",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for emo in emotions:\n",
    "#         joblib.dump(emo_features[emo], emo + \"_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9f6e07b-e3d6-48de-bd39-94aa3c3dcb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim1=128, hidden_dim2=64):\n",
    "        super(BinaryMLP, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim2, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1a08e0-1e77-4883-a9a6-60afc25d8110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "   not happy       0.93      0.92      0.92       530\n",
      "       happy       0.62      0.66      0.64       107\n",
      "\n",
      "    accuracy                           0.87       637\n",
      "   macro avg       0.77      0.79      0.78       637\n",
      "weighted avg       0.88      0.87      0.88       637\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ─── Block: Train \"happy\" binary classifier ───\n",
    "\n",
    "y_train_h = np.where(y_train == \"happy\", 1, 0)\n",
    "y_test_h  = np.where(y_test  == \"happy\", 1, 0)\n",
    "\n",
    "model_happy_svc = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    class_weight=\"balanced\",\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "model_happy_svc.fit(X_train_emo[\"happy\"], y_train_h)\n",
    "y_pred_happy = model_happy_svc.predict(X_test_emo[\"happy\"])\n",
    "print(classification_report(y_test_h, y_pred_happy, target_names=[\"not happy\",\"happy\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0f681f0-46bf-44bd-ba23-c59a48fbcb09",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not determine the shape of object type 'Series'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     19\u001b[39m X_happy_test  = torch.tensor(X_test_emo[\u001b[33m'\u001b[39m\u001b[33mhappy\u001b[39m\u001b[33m'\u001b[39m], dtype=torch.float32)\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m y_happy_test  = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m  \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mhappy\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m.unsqueeze(\u001b[32m1\u001b[39m)\n\u001b[32m     21\u001b[39m test_ds  = TensorDataset(X_happy_test, y_happy_test)\n\u001b[32m     22\u001b[39m test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
      "\u001b[31mValueError\u001b[39m: could not determine the shape of object type 'Series'"
     ]
    }
   ],
   "source": [
    "# ─── Block: Train \"happy\" binary classifier ───\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim   = X_train_emo['happy'].shape[1]\n",
    "hidden_dim1 = 256\n",
    "hidden_dim2 = 128\n",
    "lr          = 1e-3\n",
    "batch_size  = 32\n",
    "num_epochs  = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare DataLoaders\n",
    "X_happy_train = torch.tensor(X_train_emo['happy'], dtype=torch.float32)\n",
    "y_happy_train = torch.tensor((y_train == 'happy').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "train_ds = TensorDataset(X_happy_train, y_happy_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_happy_test  = torch.tensor(X_test_emo['happy'], dtype=torch.float32)\n",
    "y_happy_test  = torch.tensor((y_test  == 'happy').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "test_ds  = TensorDataset(X_happy_test, y_happy_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "model_happy = BinaryMLP(input_dim, hidden_dim1, hidden_dim2).to(device)\n",
    "criterion   = nn.BCELoss()\n",
    "optimizer   = torch.optim.Adam(model_happy.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model_happy.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_happy(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_happy.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = model_happy(xb).cpu().numpy()\n",
    "        preds = (probs > 0.3).astype(int)\n",
    "        y_pred.extend(preds.flatten().tolist())\n",
    "        y_true.extend(yb.numpy().flatten().tolist())\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['not happy', 'happy']))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[f\"Not {\"happy\"}\", \"happy\"],\n",
    "    yticklabels=[f\"Not {\"happy\"}\", \"happy\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – '{\"happy\"}' Binary Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c48739-5b7d-40ba-87ba-d71ccb6f4d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Block: Train \"angry\" binary classifier ───\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim   = X_train_emo['angry'].shape[1]\n",
    "hidden_dim1 = 256\n",
    "hidden_dim2 = 128\n",
    "lr          = 1e-3\n",
    "batch_size  = 32\n",
    "num_epochs  = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare DataLoaders\n",
    "X_angry_train = torch.tensor(X_train_emo['angry'], dtype=torch.float32)\n",
    "y_angry_train = torch.tensor((y_train == 'angry').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "train_ds = TensorDataset(X_angry_train, y_angry_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_angry_test  = torch.tensor(X_test_emo['angry'], dtype=torch.float32)\n",
    "y_angry_test  = torch.tensor((y_test  == 'angry').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "test_ds  = TensorDataset(X_angry_test, y_angry_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "model_angry = BinaryMLP(input_dim, hidden_dim1, hidden_dim2).to(device)\n",
    "criterion   = nn.BCELoss()\n",
    "optimizer   = torch.optim.Adam(model_angry.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model_angry.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_angry(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_angry.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = model_angry(xb).cpu().numpy()\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        y_pred.extend(preds.flatten().tolist())\n",
    "        y_true.extend(yb.numpy().flatten().tolist())\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['not angry', 'angry']))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[f\"Not {\"angry\"}\", \"angry\"],\n",
    "    yticklabels=[f\"Not {\"angry\"}\", \"angry\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – '{\"angry\"}' Binary Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731ca165-b640-4fe2-9ccc-200d4c1bc94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Block: Train \"disgust\" binary classifier ───\n",
    "\n",
    "y_train_d = np.where(y_train == \"disgust\", 1, 0)\n",
    "y_test_d  = np.where(y_test  == \"disgust\", 1, 0)\n",
    "\n",
    "balanced_ws = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=y_train,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight = {0: 0.95, 1: 20}\n",
    "\n",
    "model_disgust_svc = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    class_weight=class_weight,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "model_disgust_svc.fit(X_train_emo[\"disgust\"], y_train_d)\n",
    "y_pred_disgust = model_disgust_svc.predict(X_test_emo[\"disgust\"])\n",
    "print(classification_report(y_test_d, y_pred_disgust, target_names=[\"not disgust\",\"disgust\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc65a0ca-067d-40e4-a625-78f27ab43550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#joblib.dump(model_disgust_svc, \"disgust_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31778459-094f-4f5d-b1b0-2b4a0048c6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Block: Train \"disgust\" binary classifier ───\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim   = X_train_emo['disgust'].shape[1]\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "lr          = 1e-3\n",
    "batch_size  = 36\n",
    "num_epochs  = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare DataLoaders\n",
    "X_disgust_train = X_train_emo['disgust']\n",
    "y_disgust_train = np.where(y_train  == \"disgust\", 1, 0)\n",
    "\n",
    "X_disgust_test  = X_test_emo['disgust']\n",
    "y_disgust_test  = np.where(y_test  == \"disgust\", 1, 0)\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "mlp = MLPClassifier(max_iter=1000, random_state=42)\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (64,128)],\n",
    "    \"activation\":         [\"relu\",\"tanh\"],\n",
    "    \"alpha\":              [1e-3],\n",
    "    \"learning_rate\":      [\"constant\",\"adaptive\"]\n",
    "}\n",
    "digust_grid = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"recall\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "digust_grid.fit(X_disgust_train, y_disgust_train)\n",
    "\n",
    "# 5) Evaluate on validation\n",
    "y_pred = digust_grid.predict(X_disgust_test)\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_disgust_test, y_pred, target_names=['not disgust', 'disgust']))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_disgust_test, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[f\"Not {\"disgust\"}\", \"disgust\"],\n",
    "    yticklabels=[f\"Not {\"disgust\"}\", \"disgust\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – '{\"disgust\"}' Binary Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510b7b5-0b9e-4789-a29f-3312d39c7b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Block: Train \"fearful\" binary classifier ───\n",
    "\n",
    "y_train_f = np.where(y_train == \"fearful\", 1, 0)\n",
    "y_test_f  = np.where(y_test  == \"fearful\", 1, 0)\n",
    "\n",
    "balanced_ws = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=y_train,\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weight = {0: 0.75, 1: 30}\n",
    "\n",
    "model_fearful_svc = SVC(\n",
    "    kernel=\"rbf\",\n",
    "    class_weight=class_weight,\n",
    "    probability=True,\n",
    "    random_state=42\n",
    ")\n",
    "model_fearful_svc.fit(X_train_emo[\"fearful\"], y_train_f)\n",
    "y_pred_fearful = model_fearful_svc.predict(X_test_emo[\"fearful\"])\n",
    "print(classification_report(y_test_f, y_pred_fearful, target_names=[\"not fearful\",\"fearful\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51670fb9-4ecf-49ac-8f13-7bc8ddece483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Block: Train \"fearful\" binary classifier ───\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim   = X_train_emo['fearful'].shape[1]\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "lr          = 1e-3\n",
    "batch_size  = 36\n",
    "num_epochs  = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare DataLoaders\n",
    "X_fearful_train = torch.tensor(X_train_emo['fearful'], dtype=torch.float32)\n",
    "y_fearful_train = torch.tensor((y_train == 'fearful').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "train_ds = TensorDataset(X_fearful_train, y_fearful_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_fearful_test  = torch.tensor(X_test_emo['fearful'], dtype=torch.float32)\n",
    "y_fearful_test  = torch.tensor((y_test  == 'fearful').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "test_ds  = TensorDataset(X_fearful_test, y_fearful_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "model_fearful = BinaryMLP(input_dim, hidden_dim1, hidden_dim2).to(device)\n",
    "criterion   = nn.BCELoss()\n",
    "optimizer   = torch.optim.Adam(model_fearful.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model_fearful.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_fearful(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_fearful.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = model_fearful(xb).cpu().numpy()\n",
    "        preds = (probs > 0.4).astype(int)\n",
    "        y_pred.extend(preds.flatten().tolist())\n",
    "        y_true.extend(yb.numpy().flatten().tolist())\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['not fearful', 'fearful']))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[f\"Not {\"fearful\"}\", \"fearful\"],\n",
    "    yticklabels=[f\"Not {\"fearful\"}\", \"fearful\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – '{\"fearful\"}' Binary Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4eff45-6efa-4383-89d0-61d6e1d7d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if isinstance(model_fearful, torch.nn.Module):\n",
    "        # Save PyTorch model weights\n",
    "#        torch.save(model_fearful, \"fearful_model_2.pt\")\n",
    "#else:\n",
    "        # Save scikit-learn model\n",
    "#        joblib.dump(model_fearful, \"fearful_model_2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e382cd3-57e7-4d08-80ae-db82e0c0af23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Block: Train \"neutral\" binary classifier ───\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim   = X_train_emo['neutral'].shape[1]\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "lr          = 1e-3\n",
    "batch_size  = 32\n",
    "num_epochs  = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare DataLoaders\n",
    "X_neutral_train = torch.tensor(X_train_emo['neutral'], dtype=torch.float32)\n",
    "y_neutral_train = torch.tensor((y_train == 'neutral').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "train_ds = TensorDataset(X_neutral_train, y_neutral_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_neutral_test  = torch.tensor(X_test_emo['neutral'], dtype=torch.float32)\n",
    "y_neutral_test  = torch.tensor((y_test  == 'neutral').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "test_ds  = TensorDataset(X_neutral_test, y_neutral_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "model_neutral = BinaryMLP(input_dim, hidden_dim1, hidden_dim2).to(device)\n",
    "criterion   = nn.BCELoss()\n",
    "optimizer   = torch.optim.Adam(model_neutral.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model_neutral.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_neutral(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_neutral.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = model_neutral(xb).cpu().numpy()\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        y_pred.extend(preds.flatten().tolist())\n",
    "        y_true.extend(yb.numpy().flatten().tolist())\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['not neutral', 'neutral']))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[f\"Not {\"neutral\"}\", \"neutral\"],\n",
    "    yticklabels=[f\"Not {\"neutral\"}\", \"neutral\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – '{\"neutral\"}' Binary Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ef841-fb4a-4b08-bb63-b4d844cfd534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.neural_network  import MLPClassifier\n",
    "from sklearn.metrics         import classification_report, confusion_matrix\n",
    "\n",
    "# 1) Prepare your binary targets\n",
    "#    Assuming y_train is your array of string labels and X_train_emo[\"neutral\"] is your np.array\n",
    "import numpy as np\n",
    "y_train_neu = np.where(y_train == \"neutral\", 1, 0)\n",
    "y_test_neu  = np.where(y_test  == \"neutral\", 1, 0)\n",
    "\n",
    "\n",
    "selector = ColumnTransformer(\n",
    "  [\n",
    "    (\"pick_neutral\", \"passthrough\", emo_features[\"neutral\"])\n",
    "  ],\n",
    "  remainder=\"drop\"\n",
    ")\n",
    "\n",
    "# 2) Build the pipeline\n",
    "neutral_pipe = Pipeline([\n",
    "    (\"select\", selector),\n",
    "    # scale each feature to zero mean / unit var\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    # a 2-layer MLP: 128→64→1 with sigmoid (via probability=True)\n",
    "    (\"clf\", MLPClassifier(\n",
    "        hidden_layer_sizes=(128, 64),\n",
    "        activation=\"relu\",\n",
    "        alpha=1e-3,\n",
    "        learning_rate_init=1e-3,\n",
    "        solver=\"adam\",\n",
    "        max_iter=1000,         # roughly your 50 epochs × batch‐size steps\n",
    "        random_state=42,\n",
    "        verbose=False\n",
    "    ))\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 3) Fit it\n",
    "neutral_pipe.fit(X_train_emo[\"neutral\"], y_train_neu)\n",
    "\n",
    "# 4) Evaluate on the test set\n",
    "y_pred_neu = neutral_pipe.predict(X_test_emo[\"neutral\"])\n",
    "print(\"=== Neutral Binary Classification Report ===\")\n",
    "print(classification_report(y_test_neu, y_pred_neu, target_names=[\"not neutral\",\"neutral\"]))\n",
    "\n",
    "cm = confusion_matrix(y_test_neu, y_pred_neu)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[f\"Not {\"neutral\"}\", \"neutral\"],\n",
    "    yticklabels=[f\"Not {\"neutral\"}\", \"neutral\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – '{\"neutral\"}' Binary Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 5) Save the entire pipeline in one file\n",
    "joblib.dump(neutral_pipe, \"neutral_pipeline.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113b6026-b89c-4624-b45a-8f23411f58b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import joblib\n",
    "\n",
    "#if isinstance(model_neutral, torch.nn.Module):\n",
    "        # Save PyTorch model weights\n",
    "#        torch.save(model_neutral, \"neutral_model.pt\")\n",
    "#else:\n",
    "        # Save scikit-learn model\n",
    "#        joblib.dump(model_neutral, \"neutral_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cace632c-706d-40c3-94e1-20d212e32f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Block: Train \"sad\" binary classifier ───\n",
    "\n",
    "# Hyperparameters\n",
    "input_dim   = X_train_emo['sad'].shape[1]\n",
    "hidden_dim1 = 128\n",
    "hidden_dim2 = 64\n",
    "lr          = 1e-3\n",
    "batch_size  = 36\n",
    "num_epochs  = 50\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Prepare DataLoaders\n",
    "X_sad_train = torch.tensor(X_train_emo['sad'], dtype=torch.float32)\n",
    "y_sad_train = torch.tensor((y_train == 'sad').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "train_ds = TensorDataset(X_sad_train, y_sad_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "X_sad_test  = torch.tensor(X_test_emo['sad'], dtype=torch.float32)\n",
    "y_sad_test  = torch.tensor((y_test  == 'sad').astype(float), dtype=torch.float32).unsqueeze(1)\n",
    "test_ds  = TensorDataset(X_sad_test, y_sad_test)\n",
    "test_loader = DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "# Instantiate model, loss, and optimizer\n",
    "model_sad = BinaryMLP(input_dim, hidden_dim1, hidden_dim2).to(device)\n",
    "criterion   = nn.BCELoss()\n",
    "optimizer   = torch.optim.Adam(model_sad.parameters(), lr=lr)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    model_sad.train()\n",
    "    total_loss = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_sad(xb)\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * xb.size(0)\n",
    "    avg_loss = total_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch {epoch}/{num_epochs} — Loss: {avg_loss:.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "model_sad.eval()\n",
    "y_true, y_pred = [], []\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_loader:\n",
    "        xb = xb.to(device)\n",
    "        probs = model_sad(xb).cpu().numpy()\n",
    "        preds = (probs > 0.5).astype(int)\n",
    "        y_pred.extend(preds.flatten().tolist())\n",
    "        y_true.extend(yb.numpy().flatten().tolist())\n",
    "\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=['not sad', 'sad']))\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[f\"Not {\"sad\"}\", \"sad\"],\n",
    "    yticklabels=[f\"Not {\"sad\"}\", \"sad\"]\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – '{\"sad\"}' Binary Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af78bd6c-677d-4028-9939-c3095b1b5d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_models = {\n",
    "    \"happy\":    model_happy,    #SVC\n",
    "    \"angry\":    model_angry,    #MLP\n",
    "    \"disgust\":  model_disgust_svc,  #SVC\n",
    "    \"fearful\":  model_fearful,  #SVC\n",
    "    \"neutral\":  model_neutral,  #MLP\n",
    "    \"sad\":      model_sad       #MLP\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3956a54-2956-4e30-9213-8ee1fd3de9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, model in ensemble_models.items():\n",
    "#     if isinstance(model, torch.nn.Module):\n",
    "#         # Save PyTorch model weights\n",
    "#         torch.save(model, name + \"_model.pt\")\n",
    "#     else:\n",
    "#         #Save scikit-learn model\n",
    "#         joblib.dump(model, name + \"_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbbf968-1003-48c7-aa77-16c507295ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Assume:\n",
    "#   X_test_emo = { emo: numpy array shape (N, feat_dim) for each emotion }\n",
    "#   y_test     = array of true labels, shape (N,)\n",
    "\n",
    "probs_dict = {}\n",
    "for emo, clf in ensemble_models.items():\n",
    "    X_emo = X_test_emo[emo]\n",
    "    print(emo)\n",
    "    \n",
    "    if isinstance(clf, torch.nn.Module):\n",
    "        # PyTorch model: run through sigmoid net\n",
    "        clf.eval()\n",
    "        with torch.no_grad():\n",
    "            t = torch.tensor(X_emo, dtype=torch.float32).to(device)\n",
    "            probs = clf(t).cpu().numpy().flatten()\n",
    "    else:\n",
    "        # sklearn‐style model\n",
    "        probs = clf.predict_proba(X_emo)[:, 1]\n",
    "    \n",
    "    probs_dict[f\"{emo}_prob\"] = probs\n",
    "\n",
    "# Final ensemble DataFrame\n",
    "df_ensemble = pd.DataFrame(probs_dict)\n",
    "df_ensemble[\"true_label\"] = y_test\n",
    "df_ensemble.head()\n",
    "\n",
    "print(df_ensemble)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d983730f-21ea-4568-a74b-971c95de0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Encode string labels into integers\n",
    "le = LabelEncoder()\n",
    "y_meta = le.fit_transform(df_ensemble[\"true_label\"])\n",
    "x_meta = df_ensemble.drop(columns=\"true_label\")\n",
    "\n",
    "scaler2 = StandardScaler().fit(x_meta)\n",
    "x_meta = scaler2.transform(x_meta)\n",
    "\n",
    "# Split (or reuse your previous test split)\n",
    "Xm_train, Xm_val, ym_train, ym_val = train_test_split(\n",
    "    x_meta, y_meta, test_size=0.2, stratify=y_meta, random_state=42\n",
    ")\n",
    "\n",
    "meta = LogisticRegression(max_iter=500)\n",
    "meta.fit(Xm_train, ym_train)\n",
    "\n",
    "print(\"Meta‑model val accuracy:\", meta.score(Xm_val, ym_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ff8b22-3613-4252-8284-9f4d2935b3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if isinstance(meta, torch.nn.Module):\n",
    "        # Save PyTorch model weights\n",
    "#        torch.save(meta, \"metaLogisticregression.pt\")\n",
    "#else:\n",
    "        # Save scikit-learn model\n",
    "#        joblib.dump(meta, \"metaLogisticregression.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2263898e-6540-462b-babb-b95ea33e2fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if isinstance(grid, torch.nn.Module):\n",
    "        # Save PyTorch model weights\n",
    "#        torch.save(grid, \"metaMLPGrid.pt\")\n",
    "#else:\n",
    "        # Save scikit-learn model\n",
    "#        joblib.dump(grid, \"metaMLPGrid.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbc8fef-9218-4f86-bcb2-8df961415d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta_RF = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "model_meta_RF.fit(Xm_train, ym_train)\n",
    "\n",
    "y_pred_meta = model_meta_RF.predict(Xm_val)\n",
    "print(classification_report(ym_val, y_pred_meta, target_names=le.classes_))\n",
    "\n",
    "cmb = confusion_matrix(ym_val, y_pred_meta)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cmb, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=le.classes_,\n",
    "    yticklabels=le.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – RF Meta Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8cc170-177e-42fc-9f2d-136f9e1b8c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ─── Cell: Meta‑Model Training & Evaluation with Fitted LabelEncoder ───\n",
    "\n",
    "\n",
    "\n",
    "# 4) Define grid & fit\n",
    "mlp = MLPClassifier(max_iter=300, random_state=42)\n",
    "param_grid = {\n",
    "    \"hidden_layer_sizes\": [(64,), (128,), (128,64)],\n",
    "    \"activation\":         [\"relu\",\"tanh\"],\n",
    "    \"alpha\":              [1e-4, 1e-3, 1e-2],\n",
    "    \"learning_rate\":      [\"constant\",\"adaptive\"]\n",
    "}\n",
    "grid = GridSearchCV(\n",
    "    mlp,\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring=\"f1_weighted\",\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid.fit(Xm_train, ym_train)\n",
    "\n",
    "# 5) Evaluate on validation\n",
    "y_pred = grid.predict(Xm_val)\n",
    "\n",
    "print(\"\\n=== Validation Classification Report ===\")\n",
    "print(classification_report(\n",
    "    ym_val,\n",
    "    y_pred,\n",
    "    target_names=le.classes_\n",
    "))\n",
    "\n",
    "cm = confusion_matrix(ym_val, y_pred)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(\n",
    "    cm, \n",
    "    annot=True, \n",
    "    fmt=\"d\", \n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=le.classes_,\n",
    "    yticklabels=le.classes_\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(f\"Confusion Matrix – RF Meta Classifier\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2a0d27-1388-4c3d-a91f-89baa772b87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
